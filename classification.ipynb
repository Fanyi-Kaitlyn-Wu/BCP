{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4652bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     16\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/your/project/root\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m conformal_Bayes_functions \u001b[38;5;28;01mas\u001b[39;00m cb\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bayes_MCMC_functions \u001b[38;5;28;01mas\u001b[39;00m bmcmc\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from theano import tensor as tt\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "from functools import partial \n",
    "from jax.scipy.stats import norm\n",
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "from src import load_data\n",
    "from src import conformal_Bayes_functions as cb\n",
    "from src import Bayes_MCMC_functions as bmcmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "from jax.scipy.stats import norm\n",
    "import jax.scipy as jsp\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "#import from cb package\n",
    "from run_scripts.load_data import load_traintest_sparseclass\n",
    "from conformal_bayes import conformal_Bayes_functions as cb\n",
    "from conformal_bayes import Bayes_MCMC_functions as bmcmc\n",
    "\n",
    "#Define baselines\n",
    "#Split Method\n",
    "def conformal_split(alpha,y,x,x_test,seed = 100):\n",
    "    n = np.shape(y)[0]\n",
    "    n_test = np.shape(x_test)[0]\n",
    "    #Fit lasso to training set\n",
    "    n_train = int(n/2)\n",
    "    ls = LogisticRegressionCV(penalty = 'l1', solver  = 'liblinear', cv = 5, random_state = seed)\n",
    "    ls.fit(x[0:n_train],y[0:n_train])\n",
    "    resid = ls.predict_proba(x[n_train:])[:,1]\n",
    "    resid[y[n_train:]==0] =  1- resid[y[n_train:]==0]\n",
    "    resid = -np.log(np.clip(resid,1e-6,1-1e-6)) #clip for numerical stability\n",
    "    k = int(np.ceil((n/2 + 1)*(1-alpha)))\n",
    "    d = np.sort(resid)[k-1]    \n",
    "    \n",
    "    logp_test = -np.log(np.clip(ls.predict_proba(x_test),1e-6,1-1e-6))\n",
    "    region_split = logp_test <= d\n",
    "    \n",
    "    return region_split\n",
    "\n",
    "#Full Method\n",
    "def conformal_full(alpha,y,x,x_test,C,seed = 100):\n",
    "    n = np.shape(y)[0]\n",
    "    rank_cp = np.zeros(2)\n",
    "    for y_new in (0,1):\n",
    "        x_aug = np.concatenate((x,x_test),axis = 0)\n",
    "        y_aug = np.append(y,y_new)\n",
    "        ls = LogisticRegression(penalty = 'l1', solver  = 'liblinear', C = C, random_state = seed)\n",
    "        ls.fit(x_aug,y_aug)\n",
    "        resid = ls.predict_proba(x_aug)[:,1]\n",
    "        resid[y_aug==0] =  1- resid[y_aug==0]\n",
    "        resid = -np.log(resid)\n",
    "        rank_cp[y_new] = np.sum(resid>=resid[-1])/(n+1)\n",
    "    region_full = rank_cp > alpha \n",
    "    return region_full\n",
    "\n",
    "#Main run function for sparse classification\n",
    "def run_sparseclass_conformal(dataset):\n",
    "\n",
    "    #Compute intervals\n",
    "    #Load posterior samples\n",
    "    beta_post = jnp.load(\"samples/beta_post_sparseclass_{}.npy\".format(dataset))\n",
    "    intercept_post = jnp.load(\"samples/intercept_post_sparseclass_{}.npy\".format(dataset))\n",
    "\n",
    "\n",
    "    #Initialize\n",
    "    train_frac = 0.7\n",
    "    x,y,x_test,y_test,y_plot,n,d = load_traintest_sparseclass(train_frac,dataset,100)\n",
    "\n",
    "    alpha = 0.2\n",
    "    rep = np.shape(beta_post)[0]\n",
    "    n_test = np.shape(x_test)[0]\n",
    "\n",
    "    coverage_cb = np.zeros((rep,n_test))\n",
    "    coverage_bayes = np.zeros((rep,n_test))\n",
    "    coverage_split = np.zeros((rep,n_test))\n",
    "    coverage_full = np.zeros((rep,n_test))\n",
    "\n",
    "    length_cb = np.zeros((rep,n_test))\n",
    "    length_bayes = np.zeros((rep,n_test))\n",
    "    length_split = np.zeros((rep,n_test))\n",
    "    length_full= np.zeros((rep,n_test))\n",
    "    \n",
    "    p_bayes = np.zeros((rep,n_test))\n",
    "    region_bayes = np.zeros((rep,n_test,2))\n",
    "    region_cb = np.zeros((rep,n_test,2))\n",
    "    region_split = np.zeros((rep,n_test,2))\n",
    "    region_full = np.zeros((rep,n_test,2))\n",
    "\n",
    "    times_bayes = np.zeros(rep)\n",
    "    times_cb = np.zeros(rep)\n",
    "    times_split = np.zeros(rep)\n",
    "    times_full = np.zeros(rep)\n",
    "\n",
    "\n",
    "    for j in tqdm(range(rep)):\n",
    "        seed = 100 + j\n",
    "\n",
    "        #load data\n",
    "        x,y,x_test,y_test,y_plot,n,d = load_traintest_sparseclass(train_frac,dataset,seed)\n",
    "\n",
    "        #Split conformal method\n",
    "        start = time.time() \n",
    "        region_split[j] = conformal_split(alpha,y,x,x_test,seed)\n",
    "        for i in (range(n_test)):\n",
    "            coverage_split[j,i] = region_split[j,i,np.argmin(np.abs(y_test[i]-y_plot))]\n",
    "            length_split[j,i] = np.sum(region_split[j,i])\n",
    "        end = time.time()\n",
    "        times_split[j]= end-start        \n",
    "\n",
    "\n",
    "        #Full conformal method\n",
    "        start = time.time() \n",
    "        C = 1.\n",
    "        for i in (range(n_test)):\n",
    "            region_full[j,i] = conformal_full(alpha,y,x,x_test[i:i+1],C,seed)\n",
    "            coverage_full[j,i] = region_full[j,i,np.argmin(np.abs(y_test[i]-y_plot))]\n",
    "            length_full[j,i] = np.sum(region_full[j,i])\n",
    "        end = time.time()\n",
    "        times_full[j]= end-start\n",
    "\n",
    "        #Bayes\n",
    "        start = time.time()\n",
    "        @jit\n",
    "        def logistic_loglikelihood(y,x):\n",
    "            eta = (jnp.dot(beta_post[j],x.transpose())+intercept_post[j])\n",
    "            B = np.shape(eta)[0]\n",
    "            n = np.shape(eta)[1]\n",
    "            eta = eta.reshape(B,n,1)\n",
    "            temp0 = np.zeros((B,n,1))\n",
    "            logp = -jsp.special.logsumexp(jnp.concatenate((temp0,-eta),axis = 2),axis = 2) #numerically stable\n",
    "            log1p = -jsp.special.logsumexp(jnp.concatenate((temp0,eta),axis = 2),axis = 2)\n",
    "            return y*logp + (1-y)*log1p #compute likelihood samples\n",
    "        \n",
    "        for i in (range(n_test)):\n",
    "            p_bayes[j,i] = jnp.mean(jnp.exp(logistic_loglikelihood(1,x_test[i:i+1])))\n",
    "            #Compute region from p_bayes\n",
    "            if p_bayes[j,i] >(1-alpha): #only y = 1\n",
    "                region_bayes[j,i] = np.array([0,1])\n",
    "            elif (1-p_bayes[j,i]) >(1-alpha):  #only y = 0\n",
    "                region_bayes[j,i] = np.array([1,0])\n",
    "            else:\n",
    "                region_bayes[j,i] = np.array([1,1])\n",
    "            coverage_bayes[j,i] = region_bayes[j,i,np.argmin(np.abs(y_test[i]-y_plot))]\n",
    "            length_bayes[j,i] = np.sum(region_bayes[j,i])\n",
    "        end = time.time()\n",
    "        times_bayes[j]= end-start\n",
    "\n",
    "        #Conformal Bayes\n",
    "        start = time.time()\n",
    "        logp_samp_n = logistic_loglikelihood(y,x)\n",
    "        logwjk = logistic_loglikelihood(y_plot.reshape(-1,1,1),x_test)\n",
    "        #conformal\n",
    "        for i in (range(n_test)):\n",
    "            region_cb[j,i] = cb.compute_cb_region_IS(alpha,logp_samp_n,logwjk[:,:,i])\n",
    "            coverage_cb[j,i] = region_cb[j,i,np.argmin(np.abs(y_test[i]-y_plot))]\n",
    "            length_cb[j,i] = np.sum(region_cb[j,i])\n",
    "        end = time.time()\n",
    "        times_cb[j] = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f836c01",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
